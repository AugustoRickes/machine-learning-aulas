{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6727c260",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning e Otimização\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Compreender a diferença entre parâmetros e hiperparâmetros\n",
    "- Implementar Grid Search e Random Search\n",
    "- Aplicar otimização bayesiana\n",
    "- Evitar overfitting na seleção de hiperparâmetros\n",
    "\n",
    "## Pré-requisitos\n",
    "\n",
    "- Cross validation\n",
    "- Conceitos de overfitting\n",
    "- Algoritmos de ML básicos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b67590",
   "metadata": {},
   "source": [
    "## 1. Parâmetros vs Hiperparâmetros\n",
    "\n",
    "- **Parâmetros**: Aprendidos durante o treinamento (pesos, coeficientes)\n",
    "- **Hiperparâmetros**: Definidos antes do treinamento (learning rate, C, max_depth)\n",
    "\n",
    "Exemplos por algoritmo:\n",
    "\n",
    "- **Linear Regression**: Parâmetros = coeficientes; Hiperparâmetros = regularização\n",
    "- **Random Forest**: Parâmetros = splits das árvores; Hiperparâmetros = n_estimators, max_depth\n",
    "- **SVM**: Parâmetros = support vectors; Hiperparâmetros = C, gamma, kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f532d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, load_breast_cancer\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    validation_curve,\n",
    "    learning_curve,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Carregar dados\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Shape treino: {X_train.shape}\")\n",
    "print(f\"Shape teste: {X_test.shape}\")\n",
    "print(f\"Classes: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd61882",
   "metadata": {},
   "source": [
    "## 2. Baseline: Modelo com Hiperparâmetros Padrão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c76ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar modelos com hiperparâmetros padrão\n",
    "models_baseline = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "}\n",
    "\n",
    "print(\"=== Performance com Hiperparâmetros Padrão ===\")\n",
    "baseline_scores = {}\n",
    "for name, model in models_baseline.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    baseline_scores[name] = scores\n",
    "    print(f\"{name:20}: {scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a71ec",
   "metadata": {},
   "source": [
    "## 3. Grid Search - Busca Exaustiva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search para Random Forest\n",
    "print(\"=== Grid Search: Random Forest ===\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 5, 7, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, rf_param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Melhores parâmetros: {rf_grid.best_params_}\")\n",
    "print(f\"Melhor score CV: {rf_grid.best_score_:.3f}\")\n",
    "print(f\"Score no teste: {rf_grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados do Grid Search\n",
    "results_df = pd.DataFrame(rf_grid.cv_results_)\n",
    "\n",
    "# Top 10 melhores combinações\n",
    "print(\"\\n=== Top 10 Melhores Combinações ===\")\n",
    "top_results = results_df.nlargest(10, \"mean_test_score\")\n",
    "for idx, row in top_results.iterrows():\n",
    "    print(\n",
    "        f\"Score: {row['mean_test_score']:.3f} ± {row['std_test_score']:.3f} | \"\n",
    "        f\"Params: {row['params']}\"\n",
    "    )\n",
    "\n",
    "# Heatmap para n_estimators vs max_depth\n",
    "pivot_table = results_df.pivot_table(\n",
    "    values=\"mean_test_score\",\n",
    "    index=\"param_max_depth\",\n",
    "    columns=\"param_n_estimators\",\n",
    "    aggfunc=\"mean\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "plt.title(\"Grid Search: n_estimators vs max_depth\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"max_depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405975e4",
   "metadata": {},
   "source": [
    "## 4. Random Search - Busca Aleatória\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "print(\"=== Random Search: Random Forest ===\")\n",
    "\n",
    "# Distribuições para Random Search\n",
    "rf_param_dist = {\n",
    "    \"n_estimators\": randint(50, 300),\n",
    "    \"max_depth\": [3, 5, 7, 10, None],\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\": randint(1, 10),\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_dist,\n",
    "    n_iter=100,  # Número de combinações a testar\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Melhores parâmetros: {rf_random.best_params_}\")\n",
    "print(f\"Melhor score CV: {rf_random.best_score_:.3f}\")\n",
    "print(f\"Score no teste: {rf_random.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Comparar tempos de execução\n",
    "import time\n",
    "\n",
    "# Grid Search limitado\n",
    "start_time = time.time()\n",
    "small_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    {\"n_estimators\": [50, 100], \"max_depth\": [3, 5]},\n",
    "    cv=3,\n",
    ")\n",
    "small_grid.fit(X_train, y_train)\n",
    "grid_time = time.time() - start_time\n",
    "\n",
    "# Random Search\n",
    "start_time = time.time()\n",
    "quick_random = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    ")\n",
    "quick_random.fit(X_train, y_train)\n",
    "random_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTempo Grid Search (4 combinações): {grid_time:.2f}s\")\n",
    "print(f\"Tempo Random Search (10 combinações): {random_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89f807",
   "metadata": {},
   "source": [
    "## 5. Validation Curve - Analisando Um Hiperparâmetro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a13178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve para SVM - parâmetro C\n",
    "C_values = np.logspace(-3, 2, 20)  # 0.001 a 100\n",
    "\n",
    "train_scores, val_scores = validation_curve(\n",
    "    SVC(random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    param_name=\"C\",\n",
    "    param_range=C_values,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Calcular médias e desvios\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# Plotar validation curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(C_values, train_mean, \"o-\", color=\"blue\", label=\"Treino\")\n",
    "plt.fill_between(\n",
    "    C_values, train_mean - train_std, train_mean + train_std, alpha=0.2, color=\"blue\"\n",
    ")\n",
    "\n",
    "plt.semilogx(C_values, val_mean, \"o-\", color=\"red\", label=\"Validação\")\n",
    "plt.fill_between(\n",
    "    C_values, val_mean - val_std, val_mean + val_std, alpha=0.2, color=\"red\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Parâmetro C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Curve: SVM - Parâmetro C\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Encontrar melhor C\n",
    "best_c_idx = np.argmax(val_mean)\n",
    "best_c = C_values[best_c_idx]\n",
    "print(f\"Melhor C: {best_c:.3f} (Accuracy: {val_mean[best_c_idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb246ac8",
   "metadata": {},
   "source": [
    "## 6. Pipeline com Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline com pré-processamento + modelo\n",
    "print(\"=== Pipeline com Grid Search ===\")\n",
    "\n",
    "# Criar pipeline\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"classifier\", SVC(random_state=42))])\n",
    "\n",
    "# Parâmetros do pipeline\n",
    "pipe_param_grid = {\n",
    "    \"classifier__C\": [0.1, 1, 10, 100],\n",
    "    \"classifier__gamma\": [\"scale\", \"auto\", 0.01, 0.1, 1],\n",
    "    \"classifier__kernel\": [\"rbf\", \"linear\", \"poly\"],\n",
    "}\n",
    "\n",
    "pipe_grid = GridSearchCV(pipe, pipe_param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "pipe_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Melhores parâmetros: {pipe_grid.best_params_}\")\n",
    "print(f\"Melhor score CV: {pipe_grid.best_score_:.3f}\")\n",
    "print(f\"Score no teste: {pipe_grid.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Relatório detalhado\n",
    "y_pred = pipe_grid.predict(X_test)\n",
    "print(\"\\n=== Relatório de Classificação ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd7f30",
   "metadata": {},
   "source": [
    "## 7. Evitando Overfitting na Seleção de Hiperparâmetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37291331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrar overfitting com muitas tentativas\n",
    "def simulate_hyperparameter_overfitting(n_trials=100):\n",
    "    # Simular busca com muitas tentativas aleatórias\n",
    "    best_scores = []\n",
    "\n",
    "    for trial in range(1, n_trials + 1):\n",
    "        # Gerar parâmetros aleatórios\n",
    "        random_params = {\n",
    "            \"n_estimators\": np.random.randint(50, 200),\n",
    "            \"max_depth\": np.random.choice([3, 5, 7, None]),\n",
    "            \"min_samples_split\": np.random.randint(2, 10),\n",
    "        }\n",
    "\n",
    "        # Avaliar com CV\n",
    "        model = RandomForestClassifier(random_state=42, **random_params)\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=3)\n",
    "\n",
    "        # Manter o melhor até agora\n",
    "        if trial == 1:\n",
    "            best_score = scores.mean()\n",
    "        else:\n",
    "            best_score = max(best_score, scores.mean())\n",
    "\n",
    "        best_scores.append(best_score)\n",
    "\n",
    "    return best_scores\n",
    "\n",
    "\n",
    "# Simular overfitting\n",
    "overfitting_scores = simulate_hyperparameter_overfitting(100)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 101), overfitting_scores, \"b-\", alpha=0.7)\n",
    "plt.xlabel(\"Número de Tentativas\")\n",
    "plt.ylabel(\"Melhor Score CV até o momento\")\n",
    "plt.title(\"Overfitting na Seleção de Hiperparâmetros\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Score inicial: {overfitting_scores[0]:.3f}\")\n",
    "print(f\"Score após 100 tentativas: {overfitting_scores[-1]:.3f}\")\n",
    "print(f\"Melhoria aparente: {overfitting_scores[-1] - overfitting_scores[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7022356",
   "metadata": {},
   "source": [
    "## 8. Comparação Final de Todas as Abordagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo comparativo\n",
    "print(\"=== Resumo Comparativo ===\")\n",
    "\n",
    "models_final = {\n",
    "    \"Baseline RF\": RandomForestClassifier(random_state=42),\n",
    "    \"Grid Search RF\": rf_grid.best_estimator_,\n",
    "    \"Random Search RF\": rf_random.best_estimator_,\n",
    "    \"Pipeline SVM\": pipe_grid.best_estimator_,\n",
    "}\n",
    "\n",
    "final_results = {}\n",
    "for name, model in models_final.items():\n",
    "    # Score de validação cruzada\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "    # Score no conjunto de teste\n",
    "    model.fit(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    final_results[name] = {\n",
    "        \"CV_mean\": cv_scores.mean(),\n",
    "        \"CV_std\": cv_scores.std(),\n",
    "        \"Test_score\": test_score,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"{name:20}: CV = {cv_scores.mean():.3f} ± {cv_scores.std():.3f}, \"\n",
    "        f\"Test = {test_score:.3f}\"\n",
    "    )\n",
    "\n",
    "# Visualizar resultados finais\n",
    "models = list(final_results.keys())\n",
    "cv_means = [final_results[m][\"CV_mean\"] for m in models]\n",
    "cv_stds = [final_results[m][\"CV_std\"] for m in models]\n",
    "test_scores = [final_results[m][\"Test_score\"] for m in models]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(\n",
    "    x - width / 2,\n",
    "    cv_means,\n",
    "    width,\n",
    "    yerr=cv_stds,\n",
    "    label=\"Cross Validation\",\n",
    "    alpha=0.7,\n",
    "    capsize=5,\n",
    ")\n",
    "plt.bar(x + width / 2, test_scores, width, label=\"Test Set\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Comparação Final: CV vs Test Set\")\n",
    "plt.xticks(x, models, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc32133",
   "metadata": {},
   "source": [
    "## 9. Resumo e Boas Práticas\n",
    "\n",
    "### Estratégias de Busca:\n",
    "\n",
    "1. **Grid Search**: Busca exaustiva, boa para poucos parâmetros\n",
    "2. **Random Search**: Mais eficiente para muitos parâmetros\n",
    "3. **Otimização Bayesiana**: Para casos complexos e caros\n",
    "\n",
    "### Boas Práticas:\n",
    "\n",
    "- Usar **nested cross-validation** para estimativa não-viesada\n",
    "- Sempre usar **pipeline** para evitar data leakage\n",
    "- Definir **budget de tempo/tentativas** para evitar overfitting\n",
    "- Começar com **ranges amplos**, depois refinar\n",
    "- **Validar no conjunto de teste** apenas uma vez no final\n",
    "\n",
    "### Cuidados:\n",
    "\n",
    "- Muitas tentativas podem levar a overfitting nos hiperparâmetros\n",
    "- Always use proper cross-validation\n",
    "- Considerar custo computacional vs ganho de performance\n",
    "- Documentar e reproduzir configurações\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
