{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7cc84e",
   "metadata": {},
   "source": [
    "# Clustering: K-Means e DBSCAN\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Compreender aprendizado não supervisionado\n",
    "- Implementar e aplicar algoritmo K-Means\n",
    "- Entender e usar DBSCAN para clustering baseado em densidade\n",
    "- Avaliar qualidade de clusters\n",
    "- Escolher número ótimo de clusters\n",
    "\n",
    "## Pré-requisitos\n",
    "\n",
    "- Conceitos básicos de ML\n",
    "- Distâncias e métricas\n",
    "- Visualização de dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3a1be",
   "metadata": {},
   "source": [
    "## 1. Introdução ao Clustering\n",
    "\n",
    "**Clustering** é uma técnica de aprendizado não supervisionado que agrupa dados similares.\n",
    "\n",
    "### Aplicações:\n",
    "\n",
    "- **Segmentação de clientes**: Agrupar clientes por comportamento\n",
    "- **Organização de documentos**: Agrupar textos por tópico\n",
    "- **Análise de genes**: Identificar grupos de genes similares\n",
    "- **Compressão de imagens**: Reduzir cores agrupando pixels similares\n",
    "\n",
    "### Tipos de Clustering:\n",
    "\n",
    "- **Particional**: K-Means, K-Medoids\n",
    "- **Hierárquico**: Agglomerative, Divisive\n",
    "- **Baseado em densidade**: DBSCAN, OPTICS\n",
    "- **Baseado em modelo**: Gaussian Mixture Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configurar visualização\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cdcd6",
   "metadata": {},
   "source": [
    "## 2. Algoritmo K-Means\n",
    "\n",
    "### Funcionamento:\n",
    "\n",
    "1. **Inicializar** K centroides aleatoriamente\n",
    "2. **Atribuir** cada ponto ao centroide mais próximo\n",
    "3. **Recalcular** centroides como média dos pontos atribuídos\n",
    "4. **Repetir** até convergência\n",
    "\n",
    "### Características:\n",
    "\n",
    "- Clusters **esféricos** e de **tamanho similar**\n",
    "- Sensível à **inicialização**\n",
    "- Precisa definir **K** antecipadamente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação manual do K-Means\n",
    "class KMeansManual:\n",
    "    def __init__(self, k=3, max_iters=100, random_state=42):\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        # Inicializar centroides aleatoriamente\n",
    "        n_samples, n_features = X.shape\n",
    "        self.centroids = np.random.uniform(\n",
    "            X.min(axis=0), X.max(axis=0), size=(self.k, n_features)\n",
    "        )\n",
    "\n",
    "        self.history = [self.centroids.copy()]\n",
    "\n",
    "        for iteration in range(self.max_iters):\n",
    "            # Atribuir pontos aos centroides mais próximos\n",
    "            distances = np.sqrt(((X - self.centroids[:, np.newaxis]) ** 2).sum(axis=2))\n",
    "            self.labels_ = np.argmin(distances, axis=0)\n",
    "\n",
    "            # Atualizar centroides\n",
    "            new_centroids = np.array(\n",
    "                [\n",
    "                    X[self.labels_ == i].mean(axis=0)\n",
    "                    if np.any(self.labels_ == i)\n",
    "                    else self.centroids[i]\n",
    "                    for i in range(self.k)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Verificar convergência\n",
    "            if np.allclose(self.centroids, new_centroids):\n",
    "                print(f\"Convergiu em {iteration + 1} iterações\")\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "            self.history.append(self.centroids.copy())\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = np.sqrt(((X - self.centroids[:, np.newaxis]) ** 2).sum(axis=2))\n",
    "        return np.argmin(distances, axis=0)\n",
    "\n",
    "\n",
    "# Criar dataset de exemplo\n",
    "X_blobs, y_true = make_blobs(\n",
    "    n_samples=300, centers=4, n_features=2, random_state=42, cluster_std=1.5\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {X_blobs.shape}\")\n",
    "print(f\"Clusters verdadeiros: {np.unique(y_true)}\")\n",
    "\n",
    "# Visualizar dados originais\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_blobs[:, 0], X_blobs[:, 1], c=y_true, cmap=\"viridis\", alpha=0.7)\n",
    "plt.title(\"Dados Originais (com labels verdadeiros)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_blobs[:, 0], X_blobs[:, 1], alpha=0.7, color=\"gray\")\n",
    "plt.title(\"Dados sem Labels (problema real)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83348ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar K-Means manual\n",
    "kmeans_manual = KMeansManual(k=4, random_state=42)\n",
    "kmeans_manual.fit(X_blobs)\n",
    "\n",
    "# Visualizar evolução do algoritmo\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "iterations_to_show = [0, 1, 2, 3, 4, len(kmeans_manual.history) - 1]\n",
    "\n",
    "for i, iteration in enumerate(iterations_to_show):\n",
    "    if iteration < len(kmeans_manual.history):\n",
    "        centroids = kmeans_manual.history[iteration]\n",
    "\n",
    "        # Calcular labels para esta iteração\n",
    "        if iteration == 0:\n",
    "            # Primeira iteração - só mostrar centroides iniciais\n",
    "            axes[i].scatter(X_blobs[:, 0], X_blobs[:, 1], alpha=0.5, color=\"gray\")\n",
    "        else:\n",
    "            # Calcular distâncias e labels\n",
    "            distances = np.sqrt(((X_blobs - centroids[:, np.newaxis]) ** 2).sum(axis=2))\n",
    "            labels = np.argmin(distances, axis=0)\n",
    "            axes[i].scatter(\n",
    "                X_blobs[:, 0], X_blobs[:, 1], c=labels, cmap=\"viridis\", alpha=0.7\n",
    "            )\n",
    "\n",
    "        # Plotar centroides\n",
    "        axes[i].scatter(\n",
    "            centroids[:, 0], centroids[:, 1], c=\"red\", marker=\"x\", s=200, linewidths=3\n",
    "        )\n",
    "        axes[i].set_title(f\"Iteração {iteration}\")\n",
    "        axes[i].set_xlabel(\"Feature 1\")\n",
    "        axes[i].set_ylabel(\"Feature 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparar com sklearn\n",
    "kmeans_sklearn = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels_sklearn = kmeans_sklearn.fit_predict(X_blobs)\n",
    "\n",
    "# Avaliar resultados\n",
    "ari_manual = adjusted_rand_score(y_true, kmeans_manual.labels_)\n",
    "ari_sklearn = adjusted_rand_score(y_true, labels_sklearn)\n",
    "\n",
    "print(f\"Adjusted Rand Index:\")\n",
    "print(f\"  Manual: {ari_manual:.3f}\")\n",
    "print(f\"  Sklearn: {ari_sklearn:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5048af",
   "metadata": {},
   "source": [
    "## 3. Escolhendo o Número de Clusters (K)\n",
    "\n",
    "### Métodos para escolher K:\n",
    "\n",
    "1. **Elbow Method**: Buscar \"cotovelo\" na curva de inércia\n",
    "2. **Silhouette Score**: Medir qualidade da separação\n",
    "3. **Gap Statistic**: Comparar com dados aleatórios\n",
    "4. **Conhecimento do domínio**: Usar contexto do problema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método do Cotovelo (Elbow Method)\n",
    "def elbow_method(X, max_k=10):\n",
    "    inertias = []\n",
    "    k_range = range(1, max_k + 1)\n",
    "\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "\n",
    "    return k_range, inertias\n",
    "\n",
    "\n",
    "# Silhouette Score para diferentes valores de K\n",
    "def silhouette_analysis(X, max_k=10):\n",
    "    silhouette_scores = []\n",
    "    k_range = range(2, max_k + 1)  # Silhouette precisa de pelo menos 2 clusters\n",
    "\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        score = silhouette_score(X, labels)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "    return k_range, silhouette_scores\n",
    "\n",
    "\n",
    "# Aplicar métodos\n",
    "k_range_elbow, inertias = elbow_method(X_blobs, max_k=10)\n",
    "k_range_sil, sil_scores = silhouette_analysis(X_blobs, max_k=10)\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow Method\n",
    "axes[0].plot(k_range_elbow, inertias, \"bo-\")\n",
    "axes[0].set_xlabel(\"Número de Clusters (K)\")\n",
    "axes[0].set_ylabel(\"Inércia (WCSS)\")\n",
    "axes[0].set_title(\"Método do Cotovelo\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Destacar possível cotovelo\n",
    "axes[0].axvline(x=4, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"K=4 (cotovelo)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Silhouette Score\n",
    "axes[1].plot(k_range_sil, sil_scores, \"ro-\")\n",
    "axes[1].set_xlabel(\"Número de Clusters (K)\")\n",
    "axes[1].set_ylabel(\"Silhouette Score\")\n",
    "axes[1].set_title(\"Análise de Silhouette\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Destacar melhor score\n",
    "best_k = k_range_sil[np.argmax(sil_scores)]\n",
    "axes[1].axvline(\n",
    "    x=best_k, color=\"red\", linestyle=\"--\", alpha=0.7, label=f\"Melhor K={best_k}\"\n",
    ")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Método do Cotovelo sugere: K=4 (análise visual)\")\n",
    "print(f\"Silhouette Score sugere: K={best_k} (score={max(sil_scores):.3f})\")\n",
    "print(f\"Clusters verdadeiros: {len(np.unique(y_true))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167646e5",
   "metadata": {},
   "source": [
    "## 4. DBSCAN - Density-Based Clustering\n",
    "\n",
    "### Vantagens do DBSCAN:\n",
    "\n",
    "- **Não precisa definir K** antecipadamente\n",
    "- **Detecta outliers** automaticamente\n",
    "- **Clusters de formas arbitrárias**\n",
    "- **Robusto a ruído**\n",
    "\n",
    "### Parâmetros:\n",
    "\n",
    "- **eps**: Distância máxima entre pontos do mesmo cluster\n",
    "- **min_samples**: Número mínimo de pontos para formar cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9667a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar datasets com diferentes características\n",
    "datasets = {\n",
    "    \"Blobs\": make_blobs(\n",
    "        n_samples=300, centers=4, n_features=2, random_state=42, cluster_std=1.5\n",
    "    )[0],\n",
    "    \"Circles\": make_circles(n_samples=300, noise=0.1, factor=0.5, random_state=42)[0],\n",
    "    \"Moons\": make_moons(n_samples=300, noise=0.1, random_state=42)[0],\n",
    "}\n",
    "\n",
    "# Comparar K-Means vs DBSCAN\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "\n",
    "for i, (name, X) in enumerate(datasets.items()):\n",
    "    # Dados originais\n",
    "    axes[i, 0].scatter(X[:, 0], X[:, 1], alpha=0.7, color=\"gray\")\n",
    "    axes[i, 0].set_title(f\"{name} - Dados Originais\")\n",
    "\n",
    "    # K-Means\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    kmeans_labels = kmeans.fit_predict(X)\n",
    "\n",
    "    axes[i, 1].scatter(X[:, 0], X[:, 1], c=kmeans_labels, cmap=\"viridis\", alpha=0.7)\n",
    "    axes[i, 1].scatter(\n",
    "        kmeans.cluster_centers_[:, 0],\n",
    "        kmeans.cluster_centers_[:, 1],\n",
    "        c=\"red\",\n",
    "        marker=\"x\",\n",
    "        s=200,\n",
    "        linewidths=3,\n",
    "    )\n",
    "    axes[i, 1].set_title(f\"{name} - K-Means\")\n",
    "\n",
    "    # DBSCAN\n",
    "    # Ajustar parâmetros baseado no dataset\n",
    "    if name == \"Blobs\":\n",
    "        eps, min_samples = 1.5, 5\n",
    "    elif name == \"Circles\":\n",
    "        eps, min_samples = 0.3, 5\n",
    "    else:  # Moons\n",
    "        eps, min_samples = 0.3, 5\n",
    "\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    dbscan_labels = dbscan.fit_predict(X)\n",
    "\n",
    "    # Pontos de ruído (outliers) têm label -1\n",
    "    unique_labels = set(dbscan_labels)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for label, color in zip(unique_labels, colors):\n",
    "        if label == -1:\n",
    "            # Outliers em preto\n",
    "            mask = dbscan_labels == label\n",
    "            axes[i, 2].scatter(\n",
    "                X[mask, 0],\n",
    "                X[mask, 1],\n",
    "                c=\"black\",\n",
    "                marker=\"x\",\n",
    "                s=50,\n",
    "                alpha=0.7,\n",
    "                label=\"Outliers\",\n",
    "            )\n",
    "        else:\n",
    "            mask = dbscan_labels == label\n",
    "            axes[i, 2].scatter(\n",
    "                X[mask, 0], X[mask, 1], c=[color], alpha=0.7, label=f\"Cluster {label}\"\n",
    "            )\n",
    "\n",
    "    axes[i, 2].set_title(f\"{name} - DBSCAN (eps={eps}, min_samples={min_samples})\")\n",
    "\n",
    "    # Calcular métricas (quando possível)\n",
    "    if len(np.unique(kmeans_labels)) > 1:\n",
    "        kmeans_sil = silhouette_score(X, kmeans_labels)\n",
    "        axes[i, 1].text(\n",
    "            0.05,\n",
    "            0.95,\n",
    "            f\"Silhouette: {kmeans_sil:.3f}\",\n",
    "            transform=axes[i, 1].transAxes,\n",
    "            fontsize=10,\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "        )\n",
    "\n",
    "    if len(np.unique(dbscan_labels)) > 1 and -1 not in dbscan_labels:\n",
    "        dbscan_sil = silhouette_score(X, dbscan_labels)\n",
    "        axes[i, 2].text(\n",
    "            0.05,\n",
    "            0.95,\n",
    "            f\"Silhouette: {dbscan_sil:.3f}\",\n",
    "            transform=axes[i, 2].transAxes,\n",
    "            fontsize=10,\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "        )\n",
    "\n",
    "    # Mostrar número de clusters encontrados\n",
    "    n_clusters_kmeans = len(np.unique(kmeans_labels))\n",
    "    n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "    n_outliers = list(dbscan_labels).count(-1)\n",
    "\n",
    "    axes[i, 1].text(\n",
    "        0.05,\n",
    "        0.85,\n",
    "        f\"Clusters: {n_clusters_kmeans}\",\n",
    "        transform=axes[i, 1].transAxes,\n",
    "        fontsize=10,\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    axes[i, 2].text(\n",
    "        0.05,\n",
    "        0.85,\n",
    "        f\"Clusters: {n_clusters_dbscan}\\nOutliers: {n_outliers}\",\n",
    "        transform=axes[i, 2].transAxes,\n",
    "        fontsize=10,\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"lightgreen\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "# Remover labels dos eixos para clareza\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e6b941",
   "metadata": {},
   "source": [
    "## 5. Otimizando Parâmetros do DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para escolher eps: k-distance plot\n",
    "def k_distance_plot(X, k=5):\n",
    "    \"\"\"Plota k-distance para ajudar a escolher eps no DBSCAN\"\"\"\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "    # Encontrar k vizinhos mais próximos\n",
    "    neighbors = NearestNeighbors(n_neighbors=k)\n",
    "    neighbors.fit(X)\n",
    "    distances, indices = neighbors.kneighbors(X)\n",
    "\n",
    "    # Pegar distância para o k-ésimo vizinho\n",
    "    k_distances = distances[:, k - 1]\n",
    "    k_distances = np.sort(k_distances, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(len(k_distances)), k_distances, \"b-\")\n",
    "    plt.xlabel(\"Pontos ordenados por distância\")\n",
    "    plt.ylabel(f\"{k}-distance\")\n",
    "    plt.title(f'K-Distance Plot (k={k})\\nProcure por \"cotovelo\" para escolher eps')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Sugerir eps baseado no \"cotovelo\"\n",
    "    # Método simples: encontrar maior mudança na segunda derivada\n",
    "    if len(k_distances) > 10:\n",
    "        # Calcular segunda derivada\n",
    "        second_derivative = np.diff(k_distances, n=2)\n",
    "        elbow_idx = np.argmax(second_derivative) + 2  # +2 devido ao diff duplo\n",
    "        suggested_eps = k_distances[elbow_idx]\n",
    "\n",
    "        plt.axhline(\n",
    "            y=suggested_eps,\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Eps sugerido: {suggested_eps:.3f}\",\n",
    "        )\n",
    "        plt.axvline(x=elbow_idx, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return k_distances\n",
    "\n",
    "\n",
    "# Aplicar k-distance plot para dataset de círculos\n",
    "X_circles = datasets[\"Circles\"]\n",
    "k_distances = k_distance_plot(X_circles, k=5)\n",
    "\n",
    "# Testar diferentes valores de eps\n",
    "eps_values = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "min_samples = 5\n",
    "\n",
    "fig, axes = plt.subplots(1, len(eps_values), figsize=(20, 4))\n",
    "\n",
    "for i, eps in enumerate(eps_values):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(X_circles)\n",
    "\n",
    "    # Contar clusters e outliers\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_outliers = list(labels).count(-1)\n",
    "\n",
    "    # Plotar\n",
    "    unique_labels = set(labels)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for label, color in zip(unique_labels, colors):\n",
    "        if label == -1:\n",
    "            mask = labels == label\n",
    "            axes[i].scatter(\n",
    "                X_circles[mask, 0],\n",
    "                X_circles[mask, 1],\n",
    "                c=\"black\",\n",
    "                marker=\"x\",\n",
    "                s=50,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "        else:\n",
    "            mask = labels == label\n",
    "            axes[i].scatter(\n",
    "                X_circles[mask, 0], X_circles[mask, 1], c=[color], alpha=0.7\n",
    "            )\n",
    "\n",
    "    axes[i].set_title(f\"eps={eps}\\nClusters: {n_clusters}, Outliers: {n_outliers}\")\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "plt.suptitle(\"Efeito do Parâmetro eps no DBSCAN\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b2e41",
   "metadata": {},
   "source": [
    "## 6. Métricas de Avaliação de Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44fd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar múltiplas métricas\n",
    "def evaluate_clustering(X, labels, true_labels=None):\n",
    "    \"\"\"Avalia clustering com múltiplas métricas\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Métricas que não precisam de labels verdadeiros\n",
    "    if len(set(labels)) > 1 and -1 not in labels:\n",
    "        results[\"Silhouette Score\"] = silhouette_score(X, labels)\n",
    "        results[\"Calinski-Harabasz Index\"] = calinski_harabasz_score(X, labels)\n",
    "        results[\"Davies-Bouldin Index\"] = davies_bouldin_score(X, labels)\n",
    "\n",
    "    # Métricas que precisam de labels verdadeiros\n",
    "    if true_labels is not None:\n",
    "        results[\"Adjusted Rand Index\"] = adjusted_rand_score(true_labels, labels)\n",
    "\n",
    "    # Informações básicas\n",
    "    results[\"N Clusters\"] = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    results[\"N Outliers\"] = list(labels).count(-1)\n",
    "    results[\"N Samples\"] = len(labels)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Comparar algoritmos em dataset com labels conhecidos\n",
    "X_test, y_test = make_blobs(\n",
    "    n_samples=300, centers=3, n_features=2, random_state=42, cluster_std=1.0\n",
    ")\n",
    "\n",
    "# Normalizar dados (importante para alguns algoritmos)\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Aplicar diferentes algoritmos\n",
    "algorithms = {\n",
    "    \"K-Means (K=3)\": KMeans(n_clusters=3, random_state=42),\n",
    "    \"K-Means (K=2)\": KMeans(n_clusters=2, random_state=42),\n",
    "    \"K-Means (K=4)\": KMeans(n_clusters=4, random_state=42),\n",
    "    \"DBSCAN (eps=0.5)\": DBSCAN(eps=0.5, min_samples=5),\n",
    "    \"DBSCAN (eps=0.3)\": DBSCAN(eps=0.3, min_samples=5),\n",
    "}\n",
    "\n",
    "results_comparison = {}\n",
    "\n",
    "for name, algorithm in algorithms.items():\n",
    "    if \"DBSCAN\" in name:\n",
    "        labels = algorithm.fit_predict(\n",
    "            X_test_scaled\n",
    "        )  # DBSCAN se beneficia de normalização\n",
    "    else:\n",
    "        labels = algorithm.fit_predict(X_test)\n",
    "\n",
    "    results_comparison[name] = evaluate_clustering(X_test, labels, y_test)\n",
    "\n",
    "# Criar DataFrame para comparação\n",
    "comparison_df = pd.DataFrame(results_comparison).T\n",
    "print(\"Comparação de Algoritmos de Clustering:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Dados originais\n",
    "axes[0].scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=\"viridis\", alpha=0.7)\n",
    "axes[0].set_title(\"Labels Verdadeiros\")\n",
    "\n",
    "# Resultados dos algoritmos\n",
    "for i, (name, algorithm) in enumerate(algorithms.items(), 1):\n",
    "    if \"DBSCAN\" in name:\n",
    "        labels = algorithm.fit_predict(X_test_scaled)\n",
    "        X_plot = X_test_scaled\n",
    "    else:\n",
    "        labels = algorithm.fit_predict(X_test)\n",
    "        X_plot = X_test\n",
    "\n",
    "    # Plotar clusters\n",
    "    unique_labels = set(labels)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for label, color in zip(unique_labels, colors):\n",
    "        if label == -1:\n",
    "            mask = labels == label\n",
    "            axes[i].scatter(\n",
    "                X_plot[mask, 0], X_plot[mask, 1], c=\"black\", marker=\"x\", s=50, alpha=0.7\n",
    "            )\n",
    "        else:\n",
    "            mask = labels == label\n",
    "            axes[i].scatter(X_plot[mask, 0], X_plot[mask, 1], c=[color], alpha=0.7)\n",
    "\n",
    "    # Adicionar centroides para K-Means\n",
    "    if hasattr(algorithm, \"cluster_centers_\"):\n",
    "        axes[i].scatter(\n",
    "            algorithm.cluster_centers_[:, 0],\n",
    "            algorithm.cluster_centers_[:, 1],\n",
    "            c=\"red\",\n",
    "            marker=\"x\",\n",
    "            s=200,\n",
    "            linewidths=3,\n",
    "        )\n",
    "\n",
    "    axes[i].set_title(\n",
    "        f'{name}\\nARI: {results_comparison[name][\"Adjusted Rand Index\"]:.3f}'\n",
    "    )\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ba3b1",
   "metadata": {},
   "source": [
    "## 7. Aplicação Prática: Segmentação de Clientes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar dataset sintético de clientes\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "# Definir segmentos verdadeiros\n",
    "segments = {\n",
    "    \"Jovens Econômicos\": {\n",
    "        \"age\": (18, 30),\n",
    "        \"income\": (20000, 40000),\n",
    "        \"spending\": (0.3, 0.6),\n",
    "    },\n",
    "    \"Famílias Classe Média\": {\n",
    "        \"age\": (30, 50),\n",
    "        \"income\": (40000, 80000),\n",
    "        \"spending\": (0.4, 0.7),\n",
    "    },\n",
    "    \"Seniors Altos Gastos\": {\n",
    "        \"age\": (50, 70),\n",
    "        \"income\": (60000, 120000),\n",
    "        \"spending\": (0.6, 0.9),\n",
    "    },\n",
    "    \"Executivos\": {\"age\": (25, 45), \"income\": (80000, 150000), \"spending\": (0.5, 0.8)},\n",
    "}\n",
    "\n",
    "# Gerar dados\n",
    "customers_data = []\n",
    "true_segments = []\n",
    "\n",
    "for segment_name, params in segments.items():\n",
    "    n_segment = n_customers // len(segments)\n",
    "\n",
    "    ages = np.random.uniform(params[\"age\"][0], params[\"age\"][1], n_segment)\n",
    "    incomes = np.random.uniform(params[\"income\"][0], params[\"income\"][1], n_segment)\n",
    "    spending_ratios = np.random.uniform(\n",
    "        params[\"spending\"][0], params[\"spending\"][1], n_segment\n",
    "    )\n",
    "\n",
    "    # Spending score baseado em renda e ratio\n",
    "    spending_scores = (incomes * spending_ratios) / 1000  # Escala de 0-150\n",
    "\n",
    "    for i in range(n_segment):\n",
    "        customers_data.append([ages[i], incomes[i], spending_scores[i]])\n",
    "        true_segments.append(segment_name)\n",
    "\n",
    "# Converter para arrays\n",
    "X_customers = np.array(customers_data)\n",
    "true_segments = np.array(true_segments)\n",
    "\n",
    "# Criar DataFrame\n",
    "customers_df = pd.DataFrame(X_customers, columns=[\"Age\", \"Income\", \"Spending_Score\"])\n",
    "customers_df[\"True_Segment\"] = true_segments\n",
    "\n",
    "print(\"Dataset de Clientes:\")\n",
    "print(customers_df.head())\n",
    "print(f\"\\nShape: {customers_df.shape}\")\n",
    "print(f\"\\nSegmentos verdadeiros:\")\n",
    "print(customers_df[\"True_Segment\"].value_counts())\n",
    "\n",
    "# Visualizar dados\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Age vs Income\n",
    "scatter = axes[0, 0].scatter(\n",
    "    customers_df[\"Age\"],\n",
    "    customers_df[\"Income\"],\n",
    "    c=pd.Categorical(customers_df[\"True_Segment\"]).codes,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"Age\")\n",
    "axes[0, 0].set_ylabel(\"Income\")\n",
    "axes[0, 0].set_title(\"Age vs Income (por segmento verdadeiro)\")\n",
    "\n",
    "# Income vs Spending\n",
    "axes[0, 1].scatter(\n",
    "    customers_df[\"Income\"],\n",
    "    customers_df[\"Spending_Score\"],\n",
    "    c=pd.Categorical(customers_df[\"True_Segment\"]).codes,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Income\")\n",
    "axes[0, 1].set_ylabel(\"Spending Score\")\n",
    "axes[0, 1].set_title(\"Income vs Spending Score\")\n",
    "\n",
    "# Age vs Spending\n",
    "axes[1, 0].scatter(\n",
    "    customers_df[\"Age\"],\n",
    "    customers_df[\"Spending_Score\"],\n",
    "    c=pd.Categorical(customers_df[\"True_Segment\"]).codes,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Age\")\n",
    "axes[1, 0].set_ylabel(\"Spending Score\")\n",
    "axes[1, 0].set_title(\"Age vs Spending Score\")\n",
    "\n",
    "# Distribuições\n",
    "for segment in customers_df[\"True_Segment\"].unique():\n",
    "    segment_data = customers_df[customers_df[\"True_Segment\"] == segment]\n",
    "    axes[1, 1].hist(segment_data[\"Spending_Score\"], alpha=0.7, label=segment, bins=20)\n",
    "\n",
    "axes[1, 1].set_xlabel(\"Spending Score\")\n",
    "axes[1, 1].set_ylabel(\"Frequência\")\n",
    "axes[1, 1].set_title(\"Distribuição de Spending Score por Segmento\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff029a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar clustering nos dados de clientes\n",
    "X_customers_numeric = customers_df[[\"Age\", \"Income\", \"Spending_Score\"]].values\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "X_customers_scaled = scaler.fit_transform(X_customers_numeric)\n",
    "\n",
    "# Encontrar número ótimo de clusters\n",
    "k_range, inertias = elbow_method(X_customers_scaled, max_k=8)\n",
    "k_range_sil, sil_scores = silhouette_analysis(X_customers_scaled, max_k=8)\n",
    "\n",
    "# Plotar análises\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(k_range, inertias, \"bo-\")\n",
    "axes[0].set_xlabel(\"K\")\n",
    "axes[0].set_ylabel(\"Inércia\")\n",
    "axes[0].set_title(\"Elbow Method - Clientes\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(k_range_sil, sil_scores, \"ro-\")\n",
    "axes[1].set_xlabel(\"K\")\n",
    "axes[1].set_ylabel(\"Silhouette Score\")\n",
    "axes[1].set_title(\"Silhouette Analysis - Clientes\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Aplicar K-Means e DBSCAN\n",
    "optimal_k = 4  # Baseado no conhecimento do problema\n",
    "\n",
    "# K-Means\n",
    "kmeans_customers = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans_labels = kmeans_customers.fit_predict(X_customers_scaled)\n",
    "\n",
    "# DBSCAN\n",
    "dbscan_customers = DBSCAN(eps=0.5, min_samples=10)\n",
    "dbscan_labels = dbscan_customers.fit_predict(X_customers_scaled)\n",
    "\n",
    "# Avaliar resultados\n",
    "true_labels_encoded = pd.Categorical(true_segments).codes\n",
    "\n",
    "kmeans_results = evaluate_clustering(\n",
    "    X_customers_scaled, kmeans_labels, true_labels_encoded\n",
    ")\n",
    "dbscan_results = evaluate_clustering(\n",
    "    X_customers_scaled, dbscan_labels, true_labels_encoded\n",
    ")\n",
    "\n",
    "print(\"Resultados da Segmentação de Clientes:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"K-Means:\")\n",
    "for metric, value in kmeans_results.items():\n",
    "    print(\n",
    "        f\"  {metric}: {value:.3f}\"\n",
    "        if isinstance(value, float)\n",
    "        else f\"  {metric}: {value}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nDBSCAN:\")\n",
    "for metric, value in dbscan_results.items():\n",
    "    print(\n",
    "        f\"  {metric}: {value:.3f}\"\n",
    "        if isinstance(value, float)\n",
    "        else f\"  {metric}: {value}\"\n",
    "    )\n",
    "\n",
    "# Visualizar segmentação\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Segmentos verdadeiros\n",
    "axes[0].scatter(\n",
    "    customers_df[\"Income\"],\n",
    "    customers_df[\"Spending_Score\"],\n",
    "    c=true_labels_encoded,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[0].set_xlabel(\"Income\")\n",
    "axes[0].set_ylabel(\"Spending Score\")\n",
    "axes[0].set_title(\"Segmentos Verdadeiros\")\n",
    "\n",
    "# K-Means\n",
    "axes[1].scatter(\n",
    "    customers_df[\"Income\"],\n",
    "    customers_df[\"Spending_Score\"],\n",
    "    c=kmeans_labels,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[1].set_xlabel(\"Income\")\n",
    "axes[1].set_ylabel(\"Spending Score\")\n",
    "axes[1].set_title(f'K-Means (ARI: {kmeans_results[\"Adjusted Rand Index\"]:.3f})')\n",
    "\n",
    "# DBSCAN\n",
    "scatter = axes[2].scatter(\n",
    "    customers_df[\"Income\"],\n",
    "    customers_df[\"Spending_Score\"],\n",
    "    c=dbscan_labels,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[2].set_xlabel(\"Income\")\n",
    "axes[2].set_ylabel(\"Spending Score\")\n",
    "axes[2].set_title(f'DBSCAN (ARI: {dbscan_results[\"Adjusted Rand Index\"]:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análise dos clusters encontrados pelo K-Means\n",
    "customers_df[\"Cluster_KMeans\"] = kmeans_labels\n",
    "cluster_summary = customers_df.groupby(\"Cluster_KMeans\")[\n",
    "    [\"Age\", \"Income\", \"Spending_Score\"]\n",
    "].agg([\"mean\", \"std\"])\n",
    "\n",
    "print(\"\\nResumo dos Clusters (K-Means):\")\n",
    "print(\"=\" * 50)\n",
    "print(cluster_summary.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe5f06",
   "metadata": {},
   "source": [
    "## 8. Resumo e Boas Práticas\n",
    "\n",
    "### Escolha do Algoritmo:\n",
    "\n",
    "**K-Means:**\n",
    "\n",
    "- ✅ Clusters esféricos e de tamanho similar\n",
    "- ✅ Rápido e simples\n",
    "- ✅ Boa interpretabilidade (centroides)\n",
    "- ❌ Precisa definir K antecipadamente\n",
    "- ❌ Sensível a outliers e ruído\n",
    "\n",
    "**DBSCAN:**\n",
    "\n",
    "- ✅ Detecta clusters de forma arbitrária\n",
    "- ✅ Robusto a outliers\n",
    "- ✅ Não precisa definir número de clusters\n",
    "- ❌ Sensível aos parâmetros eps e min_samples\n",
    "- ❌ Dificuldade com clusters de densidade variável\n",
    "\n",
    "### Processo Recomendado:\n",
    "\n",
    "1. **Explorar dados**: Visualizar, identificar padrões\n",
    "2. **Pré-processar**: Normalizar, tratar outliers\n",
    "3. **Escolher K**: Elbow method, Silhouette analysis\n",
    "4. **Aplicar algoritmos**: Testar K-Means e DBSCAN\n",
    "5. **Avaliar**: Métricas internas e externas\n",
    "6. **Interpretar**: Dar significado aos clusters\n",
    "7. **Validar**: Verificar com conhecimento do domínio\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
