{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0193d7fb",
   "metadata": {},
   "source": [
    "# Fluxo de Projeto Machine Learning\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Compreender as etapas de um projeto ML\n",
    "- Aplicar boas práticas em cada fase\n",
    "- Conhecer aspectos éticos em dados\n",
    "\n",
    "## Pré-requisitos\n",
    "\n",
    "- Lição anterior: Introdução ao ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Configurar seeds para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configurar estilo dos gráficos\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1807fde",
   "metadata": {},
   "source": [
    "## 1. Etapas de um Projeto ML\n",
    "\n",
    "### Fluxo típico:\n",
    "\n",
    "1. **Definição do problema**\n",
    "2. **Coleta e exploração de dados**\n",
    "3. **Preparação dos dados**\n",
    "4. **Seleção e treinamento do modelo**\n",
    "5. **Avaliação do modelo**\n",
    "6. **Deploy e monitoramento**\n",
    "\n",
    "Vamos ver cada etapa com um exemplo prático:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f8384c",
   "metadata": {},
   "source": [
    "## 2. Exemplo Prático: Previsão de Preços de Casas\n",
    "\n",
    "### Etapa 1: Definição do Problema\n",
    "\n",
    "- **Objetivo**: Prever preços de casas\n",
    "- **Tipo**: Regressão (valor contínuo)\n",
    "- **Métrica**: RMSE (Root Mean Squared Error)\n",
    "- **Stakeholders**: Imobiliária, compradores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536fb12",
   "metadata": {},
   "source": [
    "### Etapa 2: Coleta e Exploração de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset sintético (baseado no conceito do Boston Housing)\n",
    "# Vamos criar dados sintéticos para evitar problemas éticos do dataset original\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 500\n",
    "data = {\n",
    "    \"rooms\": np.random.normal(6, 1, n_samples),  # número de quartos\n",
    "    \"age\": np.random.uniform(0, 100, n_samples),  # idade da casa\n",
    "    \"distance\": np.random.exponential(3, n_samples),  # distância do centro\n",
    "    \"tax_rate\": np.random.uniform(300, 700, n_samples),  # taxa de impostos\n",
    "    \"education\": np.random.uniform(10, 20, n_samples),  # índice educacional\n",
    "}\n",
    "\n",
    "# Criar target com relação com features\n",
    "price = (\n",
    "    data[\"rooms\"] * 8\n",
    "    + (100 - data[\"age\"]) * 0.3\n",
    "    + -data[\"distance\"] * 2\n",
    "    + -data[\"tax_rate\"] * 0.02\n",
    "    + data[\"education\"] * 1.5\n",
    "    + np.random.normal(0, 5, n_samples)  # ruído\n",
    ")\n",
    "\n",
    "# Garantir preços positivos\n",
    "price = np.maximum(price, 10)\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df[\"price\"] = price\n",
    "\n",
    "print(\"Dataset carregado com sucesso!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise exploratória\n",
    "print(\"=== Informações Gerais ===\")\n",
    "print(df.info())\n",
    "print(\"\\n=== Estatísticas Descritivas ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações exploratórias\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Distribuição do target\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.hist(df[\"price\"], bins=30, alpha=0.7)\n",
    "plt.xlabel(\"Preço\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.title(\"Distribuição dos Preços\")\n",
    "\n",
    "# Correlação entre features e target\n",
    "features = [\"rooms\", \"age\", \"distance\", \"tax_rate\", \"education\"]\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(2, 3, i + 2)\n",
    "    plt.scatter(df[feature], df[\"price\"], alpha=0.5)\n",
    "    plt.xlabel(feature.title())\n",
    "    plt.ylabel(\"Preço\")\n",
    "    plt.title(f\"Preço vs {feature.title()}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlação\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc5f6a",
   "metadata": {},
   "source": [
    "### Etapa 3: Preparação dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b660c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores ausentes\n",
    "print(\"Valores ausentes por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Verificar outliers\n",
    "print(\"\\nOutliers detectados (usando IQR):\")\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    print(f\"{col}: {len(outliers)} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features e target\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dados de treino: {X_train.shape}\")\n",
    "print(f\"Dados de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Converter de volta para DataFrame para manter nomes das colunas\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(\"Dados normalizados com sucesso!\")\n",
    "print(\"\\nMédias após normalização (devem ser ~0):\")\n",
    "print(X_train_scaled.mean())\n",
    "print(\"\\nDesvios padrão após normalização (devem ser ~1):\")\n",
    "print(X_train_scaled.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a0ddd",
   "metadata": {},
   "source": [
    "### Etapa 4: Seleção e Treinamento do Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Modelo treinado com sucesso!\")\n",
    "print(f\"\\nCoeficientes do modelo:\")\n",
    "for feature, coef in zip(X_train.columns, model.coef_):\n",
    "    print(f\"{feature}: {coef:.3f}\")\n",
    "print(f\"Intercept: {model.intercept_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175aa1e6",
   "metadata": {},
   "source": [
    "### Etapa 5: Avaliação do Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827922f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular métricas\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=== Métricas de Avaliação ===\")\n",
    "print(f\"RMSE Treino: {train_rmse:.3f}\")\n",
    "print(f\"RMSE Teste: {test_rmse:.3f}\")\n",
    "print(f\"R² Treino: {train_r2:.3f}\")\n",
    "print(f\"R² Teste: {test_r2:.3f}\")\n",
    "\n",
    "# Verificar overfitting\n",
    "if abs(train_rmse - test_rmse) > train_rmse * 0.1:\n",
    "    print(\"\\n⚠️ Possível overfitting detectado!\")\n",
    "else:\n",
    "    print(\"\\n✅ Modelo parece bem generalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Predito vs Real - Treino\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_train, y_train_pred, alpha=0.6)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \"r--\", lw=2)\n",
    "plt.xlabel(\"Valores Reais\")\n",
    "plt.ylabel(\"Valores Preditos\")\n",
    "plt.title(f\"Treino - R²: {train_r2:.3f}\")\n",
    "\n",
    "# Predito vs Real - Teste\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\", lw=2)\n",
    "plt.xlabel(\"Valores Reais\")\n",
    "plt.ylabel(\"Valores Preditos\")\n",
    "plt.title(f\"Teste - R²: {test_r2:.3f}\")\n",
    "\n",
    "# Resíduos\n",
    "plt.subplot(1, 3, 3)\n",
    "residuals = y_test - y_test_pred\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Valores Preditos\")\n",
    "plt.ylabel(\"Resíduos\")\n",
    "plt.title(\"Análise de Resíduos\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5312d",
   "metadata": {},
   "source": [
    "## 3. Ética em Dados e ML\n",
    "\n",
    "### Princípios importantes:\n",
    "\n",
    "1. **Privacidade**: Proteger dados pessoais\n",
    "2. **Transparência**: Explicar como o modelo funciona\n",
    "3. **Fairness**: Evitar discriminação e viés\n",
    "4. **Responsabilidade**: Assumir responsabilidade pelos resultados\n",
    "5. **Consentimento**: Obter permissão para uso dos dados\n",
    "\n",
    "### Exemplos de problemas éticos:\n",
    "\n",
    "- Algoritmos de contratação que discriminam por gênero\n",
    "- Sistemas de reconhecimento facial com viés racial\n",
    "- Uso de dados sem consentimento\n",
    "- Falta de transparência em decisões automatizadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2281637",
   "metadata": {},
   "source": [
    "## 4. Boas Práticas\n",
    "\n",
    "### Durante o projeto:\n",
    "\n",
    "- **Documentar** todas as decisões e experimentos\n",
    "- **Versionar** código e dados\n",
    "- **Validar** resultados com especialistas do domínio\n",
    "- **Testar** o modelo em dados nunca vistos\n",
    "- **Monitorar** performance em produção\n",
    "\n",
    "### Checklist de qualidade:\n",
    "\n",
    "- ✅ Problema bem definido\n",
    "- ✅ Dados explorados e limpos\n",
    "- ✅ Modelo avaliado adequadamente\n",
    "- ✅ Métricas apropriadas para o problema\n",
    "- ✅ Considerações éticas avaliadas\n",
    "- ✅ Código reprodutível\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4265f",
   "metadata": {},
   "source": [
    "## 5. Mini-Quiz\n",
    "\n",
    "**Pergunta 1:** Qual é a primeira etapa de um projeto ML?\n",
    "\n",
    "- a) Coleta de dados\n",
    "- b) Definição do problema\n",
    "- c) Treinamento do modelo\n",
    "\n",
    "**Pergunta 2:** Por que dividimos os dados em treino e teste?\n",
    "\n",
    "- a) Para acelerar o treinamento\n",
    "- b) Para economizar memória\n",
    "- c) Para avaliar a capacidade de generalização\n",
    "\n",
    "**Pergunta 3:** O que indica um possível overfitting?\n",
    "\n",
    "- a) Alta performance em treino e teste\n",
    "- b) Baixa performance em treino e teste\n",
    "- c) Alta performance em treino, baixa em teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3ef29",
   "metadata": {},
   "source": [
    "## Respostas do Quiz\n",
    "\n",
    "1. **b) Definição do problema** - Precisamos saber o que queremos resolver\n",
    "2. **c) Para avaliar a capacidade de generalização** - Teste simula dados nunca vistos\n",
    "3. **c) Alta performance em treino, baixa em teste** - Modelo decorou os dados de treino\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e90f7a9",
   "metadata": {},
   "source": [
    "## Próximos Passos\n",
    "\n",
    "Na próxima lição, começaremos a estudar:\n",
    "\n",
    "- Regressão Linear em detalhes\n",
    "- Diferentes tipos de regressão\n",
    "- Técnicas de regularização\n",
    "- Métricas específicas para regressão\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
